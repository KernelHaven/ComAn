2012-03-30 01:07:49 +0200
commit 00093a81d3f54c72215d9f402c3f88880da89a81
Author: Stefan Reinauer <reinauer@chromium.org>
Date:   Wed Nov 2 16:12:34 2011 -0700

    Add an option to keep the ROM cached after romstage
    
    Change-Id: I05f1cbd33f0cb7d80ec90c636d1607774b4a74ef
    Signed-off-by: Stefan Reinauer <reinauer@google.com>
    Reviewed-on: http://review.coreboot.org/739
    Tested-by: build bot (Jenkins)
    Reviewed-by: Stefan Reinauer <stefan.reinauer@coreboot.org>

diff --git a/src/arch/x86/include/arch/acpi.h b/src/arch/x86/include/arch/acpi.h
index 030745d..504d71b 100644
--- a/src/arch/x86/include/arch/acpi.h
+++ b/src/arch/x86/include/arch/acpi.h
@@ -1,440 +1,442 @@
 /*
  * This file is part of the coreboot project.
  *
  * Copyright (C) 2004 SUSE LINUX AG
  * Copyright (C) 2004 Nick Barker
  * Copyright (C) 2008-2009 coresystems GmbH
  * (Written by Stefan Reinauer <stepan@coresystems.de>)
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; version 2 of the License.
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
  *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA
  */
 
 /*
  * coreboot ACPI support - headers and defines.
  */
 
 #ifndef __ASM_ACPI_H
 #define __ASM_ACPI_H
 
 #if CONFIG_GENERATE_ACPI_TABLES==1
 
 #include <stdint.h>
 
 #define RSDP_SIG		"RSD PTR "  /* RSDT pointer signature */
 #define ACPI_TABLE_CREATOR	"COREBOOT"  /* Must be exactly 8 bytes long! */
 #define OEM_ID			"CORE  "    /* Must be exactly 6 bytes long! */
 #define ASLC			"CORE"      /* Must be exactly 4 bytes long! */
 
 /* RSDP (Root System Description Pointer) */
 typedef struct acpi_rsdp {
 	char  signature[8];	/* RSDP signature */
 	u8    checksum;		/* Checksum of the first 20 bytes */
 	char  oem_id[6];	/* OEM ID */
 	u8    revision;		/* 0 for ACPI 1.0, 2 for ACPI 2.0/3.0/4.0 */
 	u32   rsdt_address;	/* Physical address of RSDT (32 bits) */
 	u32   length;		/* Total RSDP length (incl. extended part) */
 	u64   xsdt_address;	/* Physical address of XSDT (64 bits) */
 	u8    ext_checksum;	/* Checksum of the whole table */
 	u8    reserved[3];
 } __attribute__ ((packed)) acpi_rsdp_t;
 /* Note: ACPI 1.0 didn't have length, xsdt_address, and ext_checksum. */
 
 /* GAS (Generic Address Structure) */
 typedef struct acpi_gen_regaddr {
 	u8  space_id;		/* Address space ID */
 	u8  bit_width;		/* Register size in bits */
 	u8  bit_offset;		/* Register bit offset */
 	u8  resv;		/* FIXME: Access size in ACPI 2.0/3.0/4.0 */
 	u32 addrl;		/* Register address, low 32 bits */
 	u32 addrh;		/* Register address, high 32 bits */
 } __attribute__ ((packed)) acpi_addr_t;
 
 #define ACPI_ADDRESS_SPACE_MEMORY	   0	/* System memory */
 #define ACPI_ADDRESS_SPACE_IO		   1	/* System I/O */
 #define ACPI_ADDRESS_SPACE_PCI		   2	/* PCI config space */
 #define ACPI_ADDRESS_SPACE_EC		   3	/* Embedded controller */
 #define ACPI_ADDRESS_SPACE_SMBUS	   4	/* SMBus */
 #define ACPI_ADDRESS_SPACE_FIXED	0x7f	/* Functional fixed hardware */
 /* 0x80-0xbf: Reserved */
 /* 0xc0-0xff: OEM defined */
 
 /* Generic ACPI header, provided by (almost) all tables */
 typedef struct acpi_table_header {
 	char signature[4];           /* ACPI signature (4 ASCII characters) */
 	u32  length;                 /* Table length in bytes (incl. header) */
 	u8   revision;               /* Table version (not ACPI version!) */
 	u8   checksum;               /* To make sum of entire table == 0 */
 	char oem_id[6];              /* OEM identification */
 	char oem_table_id[8];        /* OEM table identification */
 	u32  oem_revision;           /* OEM revision number */
 	char asl_compiler_id[4];     /* ASL compiler vendor ID */
 	u32  asl_compiler_revision;  /* ASL compiler revision number */
 } __attribute__ ((packed)) acpi_header_t;
 
 /* A maximum number of 32 ACPI tables ought to be enough for now. */
 #define MAX_ACPI_TABLES 32
 
 /* RSDT (Root System Description Table) */
 typedef struct acpi_rsdt {
 	struct acpi_table_header header;
 	u32 entry[MAX_ACPI_TABLES];
 } __attribute__ ((packed)) acpi_rsdt_t;
 
 /* XSDT (Extended System Description Table) */
 typedef struct acpi_xsdt {
 	struct acpi_table_header header;
 	u64 entry[MAX_ACPI_TABLES];
 } __attribute__ ((packed)) acpi_xsdt_t;
 
 /* HPET timers */
 typedef struct acpi_hpet {
 	struct acpi_table_header header;
 	u32 id;
 	struct acpi_gen_regaddr addr;
 	u8 number;
 	u16 min_tick;
 	u8 attributes;
 } __attribute__ ((packed)) acpi_hpet_t;
 
 /* MCFG (PCI Express MMIO config space BAR description table) */
 typedef struct acpi_mcfg {
 	struct acpi_table_header header;
 	u8 reserved[8];
 } __attribute__ ((packed)) acpi_mcfg_t;
 
 typedef struct acpi_mcfg_mmconfig {
 	u32 base_address;
 	u32 base_reserved;
 	u16 pci_segment_group_number;
 	u8 start_bus_number;
 	u8 end_bus_number;
 	u8 reserved[4];
 } __attribute__ ((packed)) acpi_mcfg_mmconfig_t;
 
 /* SRAT (System Resource Affinity Table) */
 typedef struct acpi_srat {
 	struct acpi_table_header header;
 	u32 resv;
 	u64 resv1;
 	/* Followed by static resource allocation structure[n] */
 } __attribute__ ((packed)) acpi_srat_t;
 
 /* SRAT: Processor Local APIC/SAPIC Affinity Structure */
 typedef struct acpi_srat_lapic {
 	u8 type;			/* Type (0) */
 	u8 length;			/* Length in bytes (16) */
 	u8 proximity_domain_7_0;	/* Proximity domain bits[7:0] */
 	u8 apic_id;			/* Local APIC ID */
 	u32 flags; /* Enable bit 0 = 1, other bits reserved to 0 */
 	u8 local_sapic_eid;		/* Local SAPIC EID */
 	u8 proximity_domain_31_8[3];	/* Proximity domain bits[31:8] */
 	u32 resv;			/* TODO: Clock domain in ACPI 4.0. */
 } __attribute__ ((packed)) acpi_srat_lapic_t;
 
 /* SRAT: Memory Affinity Structure */
 typedef struct acpi_srat_mem {
 	u8 type;			/* Type (1) */
 	u8 length;			/* Length in bytes (40) */
 	u32 proximity_domain;		/* Proximity domain */
 	u16 resv;
 	u32 base_address_low;		/* Mem range base address, low */
 	u32 base_address_high;		/* Mem range base address, high */
 	u32 length_low;			/* Mem range length, low */
 	u32 length_high;		/* Mem range length, high */
 	u32 resv1;
 	u32 flags; /* Enable bit 0, hot pluggable bit 1; Non Volatile bit 2, other bits reserved to 0 */
 	u32 resv2[2];
 } __attribute__ ((packed)) acpi_srat_mem_t;
 
 /* SLIT (System Locality Distance Information Table) */
 typedef struct acpi_slit {
 	struct acpi_table_header header;
 	/* Followed by static resource allocation 8+byte[num*num] */
 } __attribute__ ((packed)) acpi_slit_t;
 
 /* MADT (Multiple APIC Description Table) */
 typedef struct acpi_madt {
 	struct acpi_table_header header;
 	u32 lapic_addr;			/* Local APIC address */
 	u32 flags;			/* Multiple APIC flags */
 } __attribute__ ((packed)) acpi_madt_t;
 
 /* MADT: APIC Structure Types */
 /* TODO: Convert to ALLCAPS. */
 enum acpi_apic_types {
 	LocalApic		= 0,	/* Processor local APIC */
 	IOApic			= 1,	/* I/O APIC */
 	IRQSourceOverride	= 2,	/* Interrupt source override */
 	NMIType			= 3,	/* NMI source */
 	LocalApicNMI		= 4,	/* Local APIC NMI */
 	LApicAddressOverride	= 5,	/* Local APIC address override */
 	IOSApic			= 6,	/* I/O SAPIC */
 	LocalSApic		= 7,	/* Local SAPIC */
 	PlatformIRQSources	= 8,	/* Platform interrupt sources */
 	Localx2Apic		= 9,	/* Processor local x2APIC */
 	Localx2ApicNMI		= 10,	/* Local x2APIC NMI */
 	/* 0x0b-0x7f: Reserved */
 	/* 0x80-0xff: Reserved for OEM use */
 };
 
 /* MADT: Processor Local APIC Structure */
 typedef struct acpi_madt_lapic {
 	u8 type;			/* Type (0) */
 	u8 length;			/* Length in bytes (8) */
 	u8 processor_id;		/* ACPI processor ID */
 	u8 apic_id;			/* Local APIC ID */
 	u32 flags;			/* Local APIC flags */
 } __attribute__ ((packed)) acpi_madt_lapic_t;
 
 /* MADT: Local APIC NMI Structure */
 typedef struct acpi_madt_lapic_nmi {
 	u8 type;			/* Type (4) */
 	u8 length;			/* Length in bytes (6) */
 	u8 processor_id;		/* ACPI processor ID */
 	u16 flags;			/* MPS INTI flags */
 	u8 lint;			/* Local APIC LINT# */
 } __attribute__ ((packed)) acpi_madt_lapic_nmi_t;
 
 /* MADT: I/O APIC Structure */
 typedef struct acpi_madt_ioapic {
 	u8 type;			/* Type (1) */
 	u8 length;			/* Length in bytes (12) */
 	u8 ioapic_id;			/* I/O APIC ID */
 	u8 reserved;
 	u32 ioapic_addr;		/* I/O APIC address */
 	u32 gsi_base;			/* Global system interrupt base */
 } __attribute__ ((packed)) acpi_madt_ioapic_t;
 
 /* MADT: Interrupt Source Override Structure */
 typedef struct acpi_madt_irqoverride {
 	u8 type;			/* Type (2) */
 	u8 length;			/* Length in bytes (10) */
 	u8 bus;				/* ISA (0) */
 	u8 source;			/* Bus-relative int. source (IRQ) */
 	u32 gsirq;			/* Global system interrupt */
 	u16 flags;			/* MPS INTI flags */
 } __attribute__ ((packed)) acpi_madt_irqoverride_t;
 
 /* FADT (Fixed ACPI Description Table) */
 typedef struct acpi_fadt {
 	struct acpi_table_header header;
 	u32 firmware_ctrl;
 	u32 dsdt;
 	u8 model;
 	u8 preferred_pm_profile;
 	u16 sci_int;
 	u32 smi_cmd;
 	u8 acpi_enable;
 	u8 acpi_disable;
 	u8 s4bios_req;
 	u8 pstate_cnt;
 	u32 pm1a_evt_blk;
 	u32 pm1b_evt_blk;
 	u32 pm1a_cnt_blk;
 	u32 pm1b_cnt_blk;
 	u32 pm2_cnt_blk;
 	u32 pm_tmr_blk;
 	u32 gpe0_blk;
 	u32 gpe1_blk;
 	u8 pm1_evt_len;
 	u8 pm1_cnt_len;
 	u8 pm2_cnt_len;
 	u8 pm_tmr_len;
 	u8 gpe0_blk_len;
 	u8 gpe1_blk_len;
 	u8 gpe1_base;
 	u8 cst_cnt;
 	u16 p_lvl2_lat;
 	u16 p_lvl3_lat;
 	u16 flush_size;
 	u16 flush_stride;
 	u8 duty_offset;
 	u8 duty_width;
 	u8 day_alrm;
 	u8 mon_alrm;
 	u8 century;
 	u16 iapc_boot_arch;
 	u8 res2;
 	u32 flags;
 	struct acpi_gen_regaddr reset_reg;
 	u8 reset_value;
 	u8 res3;
 	u8 res4;
 	u8 res5;
 	u32 x_firmware_ctl_l;
 	u32 x_firmware_ctl_h;
 	u32 x_dsdt_l;
 	u32 x_dsdt_h;
 	struct acpi_gen_regaddr x_pm1a_evt_blk;
 	struct acpi_gen_regaddr x_pm1b_evt_blk;
 	struct acpi_gen_regaddr x_pm1a_cnt_blk;
 	struct acpi_gen_regaddr x_pm1b_cnt_blk;
 	struct acpi_gen_regaddr x_pm2_cnt_blk;
 	struct acpi_gen_regaddr x_pm_tmr_blk;
 	struct acpi_gen_regaddr x_gpe0_blk;
 	struct acpi_gen_regaddr x_gpe1_blk;
 } __attribute__ ((packed)) acpi_fadt_t;
 
 /* FADT Feature Flags */
 #define ACPI_FADT_WBINVD		(1 << 0)
 #define ACPI_FADT_WBINVD_FLUSH		(1 << 1)
 #define ACPI_FADT_C1_SUPPORTED		(1 << 2)
 #define ACPI_FADT_C2_MP_SUPPORTED	(1 << 3)
 #define ACPI_FADT_POWER_BUTTON		(1 << 4)
 #define ACPI_FADT_SLEEP_BUTTON		(1 << 5)
 #define ACPI_FADT_FIXED_RTC		(1 << 6)
 #define ACPI_FADT_S4_RTC_WAKE		(1 << 7)
 #define ACPI_FADT_32BIT_TIMER		(1 << 8)
 #define ACPI_FADT_DOCKING_SUPPORTED	(1 << 9)
 #define ACPI_FADT_RESET_REGISTER	(1 << 10)
 #define ACPI_FADT_SEALED_CASE		(1 << 11)
 #define ACPI_FADT_HEADLESS		(1 << 12)
 #define ACPI_FADT_SLEEP_TYPE		(1 << 13)
 #define ACPI_FADT_PCI_EXPRESS_WAKE	(1 << 14)
 #define ACPI_FADT_PLATFORM_CLOCK	(1 << 15)
 #define ACPI_FADT_S4_RTC_VALID		(1 << 16)
 #define ACPI_FADT_REMOTE_POWER_ON	(1 << 17)
 #define ACPI_FADT_APIC_CLUSTER		(1 << 18)
 #define ACPI_FADT_APIC_PHYSICAL		(1 << 19)
 /* Bits 20-31: reserved */
 
 /* FADT Boot Architecture Flags */
 #define ACPI_FADT_LEGACY_DEVICES	(1 << 0)
 #define ACPI_FADT_8042			(1 << 1)
 #define ACPI_FADT_VGA_NOT_PRESENT	(1 << 2)
 #define ACPI_FADT_MSI_NOT_SUPPORTED	(1 << 3)
 #define ACPI_FADT_NO_PCIE_ASPM_CONTROL	(1 << 4)
 
 /* FADT Preferred Power Management Profile */
 enum acpi_preferred_pm_profiles {
 	PM_UNSPECIFIED		= 0,
 	PM_DESKTOP		= 1,
 	PM_MOBILE		= 2,
 	PM_WORKSTATION		= 3,
 	PM_ENTERPRISE_SERVER	= 4,
 	PM_SOHO_SERVER  	= 5,
 	PM_APPLIANCE_PC		= 6,
 	PM_PERFORMANCE_SERVER	= 7,
 };
 
 /* FACS (Firmware ACPI Control Structure) */
 typedef struct acpi_facs {
 	char signature[4];			/* "FACS" */
 	u32 length;				/* Length in bytes (>= 64) */
 	u32 hardware_signature;			/* Hardware signature */
 	u32 firmware_waking_vector;		/* Firmware waking vector */
 	u32 global_lock;			/* Global lock */
 	u32 flags;				/* FACS flags */
 	u32 x_firmware_waking_vector_l;		/* X FW waking vector, low */
 	u32 x_firmware_waking_vector_h;		/* X FW waking vector, high */
 	u8 version;				/* ACPI 4.0: 2 */
 	u8 resv[31];				/* FIXME: 4.0: ospm_flags */
 } __attribute__ ((packed)) acpi_facs_t;
 
 /* FACS flags */
 #define ACPI_FACS_S4BIOS_F	(1 << 0)
 #define ACPI_FACS_64BIT_WAKE_F	(1 << 1)
 /* Bits 31..2: reserved */
 
 /* ECDT (Embedded Controller Boot Resources Table) */
 typedef struct acpi_ecdt {
 	struct acpi_table_header header;
 	struct acpi_gen_regaddr ec_control;	/* EC control register */
 	struct acpi_gen_regaddr ec_data;	/* EC data register */
 	u32 uid;				/* UID */
 	u8 gpe_bit;				/* GPE bit */
 	u8 ec_id[];				/* EC ID  */
 } __attribute__ ((packed)) acpi_ecdt_t;
 
 /* These are implemented by the target port or north/southbridge. */
 unsigned long write_acpi_tables(unsigned long addr);
 unsigned long acpi_fill_madt(unsigned long current);
 unsigned long acpi_fill_mcfg(unsigned long current);
 unsigned long acpi_fill_srat(unsigned long current);
 unsigned long acpi_fill_slit(unsigned long current);
 unsigned long acpi_fill_ssdt_generator(unsigned long current,
 				       const char *oem_table_id);
 void acpi_create_ssdt_generator(acpi_header_t *ssdt, const char *oem_table_id);
 void acpi_create_fadt(acpi_fadt_t *fadt,acpi_facs_t *facs, void *dsdt);
 
 void update_ssdt(void *ssdt);
 void update_ssdtx(void *ssdtx, int i);
 
 /* These can be used by the target port. */
 u8 acpi_checksum(u8 *table, u32 length);
 
 void acpi_add_table(acpi_rsdp_t *rsdp, void *table);
 
 int acpi_create_madt_lapic(acpi_madt_lapic_t *lapic, u8 cpu, u8 apic);
 int acpi_create_madt_ioapic(acpi_madt_ioapic_t *ioapic, u8 id, u32 addr,
 			    u32 gsi_base);
 int acpi_create_madt_irqoverride(acpi_madt_irqoverride_t *irqoverride,
 				 u8 bus, u8 source, u32 gsirq, u16 flags);
 int acpi_create_madt_lapic_nmi(acpi_madt_lapic_nmi_t *lapic_nmi, u8 cpu,
 			       u16 flags, u8 lint);
 void acpi_create_madt(acpi_madt_t *madt);
 unsigned long acpi_create_madt_lapics(unsigned long current);
 unsigned long acpi_create_madt_lapic_nmis(unsigned long current, u16 flags,
 					  u8 lint);
 
 int acpi_create_srat_lapic(acpi_srat_lapic_t *lapic, u8 node, u8 apic);
 int acpi_create_srat_mem(acpi_srat_mem_t *mem, u8 node, u32 basek,u32 sizek,
 			 u32 flags);
 int acpi_create_mcfg_mmconfig(acpi_mcfg_mmconfig_t *mmconfig, u32 base,
 			      u16 seg_nr, u8 start, u8 end);
 unsigned long acpi_create_srat_lapics(unsigned long current);
 void acpi_create_srat(acpi_srat_t *srat);
 
 void acpi_create_slit(acpi_slit_t *slit);
 
 void acpi_create_hpet(acpi_hpet_t *hpet);
 
 void acpi_create_mcfg(acpi_mcfg_t *mcfg);
 
 void acpi_create_facs(acpi_facs_t *facs);
 
 #if CONFIG_HAVE_ACPI_SLIC
 unsigned long acpi_create_slic(unsigned long current);
 #endif
 
 void acpi_write_rsdt(acpi_rsdt_t *rsdt);
 void acpi_write_xsdt(acpi_xsdt_t *xsdt);
 void acpi_write_rsdp(acpi_rsdp_t *rsdp, acpi_rsdt_t *rsdt, acpi_xsdt_t *xsdt);
 
 #if CONFIG_HAVE_ACPI_RESUME
 /* 0 = S0, 1 = S1 ...*/
 extern u8 acpi_slp_type;
 
 void suspend_resume(void);
 void *acpi_find_wakeup_vector(void);
 void *acpi_get_wakeup_rsdp(void);
 void acpi_jump_to_wakeup(void *wakeup_addr);
 
 int acpi_get_sleep_type(void);
-
+#else
+#define acpi_slp_type 0
 #endif
 
 /* northbridge/amd/amdfam10/amdfam10_acpi.c */
 unsigned long acpi_add_ssdt_pstates(acpi_rsdp_t *rsdp, unsigned long current);
 
 /* cpu/intel/speedstep/acpi.c */
 void generate_cpu_entries(void);
 
 #else // CONFIG_GENERATE_ACPI_TABLES
 
 #define write_acpi_tables(start) (start)
+#define acpi_slp_type 0
 
 #endif
 
 #endif
diff --git a/src/cpu/x86/Kconfig b/src/cpu/x86/Kconfig
index d2809f8..6894622 100644
--- a/src/cpu/x86/Kconfig
+++ b/src/cpu/x86/Kconfig
@@ -1,43 +1,45 @@
 config SERIAL_CPU_INIT
 	bool
 	default y
 
 config WAIT_BEFORE_CPUS_INIT
 	bool
 	default n
 
 config UDELAY_IO
 	bool
 	default y if !UDELAY_LAPIC && !UDELAY_TSC
 	default n
 
 config UDELAY_LAPIC
 	bool
 	default n
 
 config UDELAY_TSC
 	bool
 	default n
 
 config UDELAY_TIMER2
 	bool
 	default n
 
 config TSC_CALIBRATE_WITH_IO
 	bool
 	default n
 
 config XIP_ROM_SIZE
 	hex
 	default ROM_SIZE if ROMCC
 	default 0x10000
 
 config CPU_ADDR_BITS
 	int
 	default 36
 
 config LOGICAL_CPUS
 	bool
 	default y
 
-
+config CACHE_ROM
+	bool
+	default n
diff --git a/src/cpu/x86/lapic/Makefile.inc b/src/cpu/x86/lapic/Makefile.inc
index af20956..f3fcadc 100644
--- a/src/cpu/x86/lapic/Makefile.inc
+++ b/src/cpu/x86/lapic/Makefile.inc
@@ -1,4 +1,5 @@
 ramstage-y += lapic.c
 ramstage-y += lapic_cpu_init.c
 ramstage-y += secondary.S
 ramstage-$(CONFIG_UDELAY_LAPIC) += apic_timer.c
+ramstage-y += boot_cpu.c
diff --git a/src/cpu/x86/lapic/boot_cpu.c b/src/cpu/x86/lapic/boot_cpu.c
index 87418d0..0fb9d5d 100644
--- a/src/cpu/x86/lapic/boot_cpu.c
+++ b/src/cpu/x86/lapic/boot_cpu.c
@@ -1,15 +1,16 @@
+#include <cpu/x86/lapic.h>
 #include <cpu/x86/msr.h>
 
 #if CONFIG_SMP
-static int boot_cpu(void)
+int boot_cpu(void)
 {
 	int bsp;
 	msr_t msr;
 	msr = rdmsr(0x1b);
 	bsp = !!(msr.lo & (1 << 8));
 	return bsp;
 }
 #else
 #define boot_cpu(x) 1
 #endif
 
diff --git a/src/cpu/x86/mtrr/mtrr.c b/src/cpu/x86/mtrr/mtrr.c
index 46d8e2d..9015ad4 100644
--- a/src/cpu/x86/mtrr/mtrr.c
+++ b/src/cpu/x86/mtrr/mtrr.c
@@ -1,501 +1,513 @@
 /*
  * mtrr.c: setting MTRR to decent values for cache initialization on P6
  *
  * Derived from intel_set_mtrr in intel_subr.c and mtrr.c in linux kernel
  *
  * Copyright 2000 Silicon Integrated System Corporation
  *
  *	This program is free software; you can redistribute it and/or modify
  *	it under the terms of the GNU General Public License as published by
  *	the Free Software Foundation; either version 2 of the License, or
  *	(at your option) any later version.
  *
  *	This program is distributed in the hope that it will be useful,
  *	but WITHOUT ANY WARRANTY; without even the implied warranty of
  *	MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  *	GNU General Public License for more details.
  *
  *	You should have received a copy of the GNU General Public License
  *	along with this program; if not, write to the Free Software
  *	Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
  *
  *
  * Reference: Intel Architecture Software Developer's Manual, Volume 3: System Programming
  */
 
 /*
         2005.1 yhlu add NC support to spare mtrrs for 64G memory above installed
 	2005.6 Eric add address bit in x86_setup_mtrrs
 	2005.6 yhlu split x86_setup_var_mtrrs and x86_setup_fixed_mtrrs,
 		for AMD, it will not use x86_setup_fixed_mtrrs
 */
 
 #include <stddef.h>
 #include <console/console.h>
 #include <device/device.h>
 #include <cpu/x86/msr.h>
 #include <cpu/x86/mtrr.h>
 #include <cpu/x86/cache.h>
+#include <cpu/x86/lapic.h>
 #include <arch/cpu.h>
+#include <arch/acpi.h>
 
 #if CONFIG_GFXUMA
 extern uint64_t uma_memory_base, uma_memory_size;
 #endif
 
 static unsigned int mtrr_msr[] = {
 	MTRRfix64K_00000_MSR, MTRRfix16K_80000_MSR, MTRRfix16K_A0000_MSR,
 	MTRRfix4K_C0000_MSR, MTRRfix4K_C8000_MSR, MTRRfix4K_D0000_MSR, MTRRfix4K_D8000_MSR,
 	MTRRfix4K_E0000_MSR, MTRRfix4K_E8000_MSR, MTRRfix4K_F0000_MSR, MTRRfix4K_F8000_MSR,
 };
 
-
 void enable_fixed_mtrr(void)
 {
 	msr_t msr;
 
 	msr = rdmsr(MTRRdefType_MSR);
 	msr.lo |= 0xc00;
 	wrmsr(MTRRdefType_MSR, msr);
 }
 
 static void enable_var_mtrr(void)
 {
 	msr_t msr;
 
 	msr = rdmsr(MTRRdefType_MSR);
 	msr.lo |= MTRRdefTypeEn;
 	wrmsr(MTRRdefType_MSR, msr);
 }
 
 /* setting variable mtrr, comes from linux kernel source */
 static void set_var_mtrr(
 	unsigned int reg, unsigned long basek, unsigned long sizek,
 	unsigned char type, unsigned address_bits)
 {
 	msr_t base, mask;
 	unsigned address_mask_high;
 
         if (reg >= 8)
                 return;
 
         // it is recommended that we disable and enable cache when we
         // do this.
         if (sizek == 0) {
         	disable_cache();
 
                 msr_t zero;
                 zero.lo = zero.hi = 0;
                 /* The invalid bit is kept in the mask, so we simply clear the
                    relevant mask register to disable a range. */
                 wrmsr (MTRRphysMask_MSR(reg), zero);
 
         	enable_cache();
 		return;
         }
 
 
 	address_mask_high = ((1u << (address_bits - 32u)) - 1u);
 
 	base.hi = basek >> 22;
 	base.lo  = basek << 10;
 
 	printk(BIOS_SPEW, "ADDRESS_MASK_HIGH=%#x\n", address_mask_high);
 
 	if (sizek < 4*1024*1024) {
 		mask.hi = address_mask_high;
 		mask.lo = ~((sizek << 10) -1);
 	}
 	else {
 		mask.hi = address_mask_high & (~((sizek >> 22) -1));
 		mask.lo = 0;
 	}
 
 	// it is recommended that we disable and enable cache when we
 	// do this.
 	disable_cache();
 
 	/* Bit 32-35 of MTRRphysMask should be set to 1 */
 	base.lo |= type;
 	mask.lo |= MTRRphysMaskValid;
 	wrmsr (MTRRphysBase_MSR(reg), base);
 	wrmsr (MTRRphysMask_MSR(reg), mask);
 
 	enable_cache();
 }
 
 /* fms: find most sigificant bit set, stolen from Linux Kernel Source. */
 static inline unsigned int fms(unsigned int x)
 {
 	int r;
 
 	__asm__("bsrl %1,%0\n\t"
 	        "jnz 1f\n\t"
 	        "movl $0,%0\n"
 	        "1:" : "=r" (r) : "g" (x));
 	return r;
 }
 
 /* fls: find least sigificant bit set */
 static inline unsigned int fls(unsigned int x)
 {
 	int r;
 
 	__asm__("bsfl %1,%0\n\t"
 	        "jnz 1f\n\t"
 	        "movl $32,%0\n"
 	        "1:" : "=r" (r) : "g" (x));
 	return r;
 }
 
 /* setting up variable and fixed mtrr
  *
  * From Intel Vol. III Section 9.12.4, the Range Size and Base Alignment has some kind of requirement:
  *	1. The range size must be 2^N byte for N >= 12 (i.e 4KB minimum).
  *	2. The base address must be 2^N aligned, where the N here is equal to the N in previous
  *	   requirement. So a 8K range must be 8K aligned not 4K aligned.
  *
  * These requirement is meet by "decompositing" the ramsize into Sum(Cn * 2^n, n = [0..N], Cn = [0, 1]).
  * For Cm = 1, there is a WB range of 2^m size at base address Sum(Cm * 2^m, m = [N..n]).
  * A 124MB (128MB - 4MB SMA) example:
  * 	ramsize = 124MB == 64MB (at 0MB) + 32MB (at 64MB) + 16MB (at 96MB ) + 8MB (at 112MB) + 4MB (120MB).
  * But this wastes a lot of MTRR registers so we use another more "aggresive" way with Uncacheable Regions.
  *
  * In the Uncacheable Region scheme, we try to cover the whole ramsize by one WB region as possible,
  * If (an only if) this can not be done we will try to decomposite the ramesize, the mathematical formula
  * whould be ramsize = Sum(Cn * 2^n, n = [0..N], Cn = [-1, 0, 1]). For Cn = -1, a Uncachable Region is used.
  * The same 124MB example:
  * 	ramsize = 124MB == 128MB WB (at 0MB) + 4MB UC (at 124MB)
  * or a 156MB (128MB + 32MB - 4MB SMA) example:
  *	ramsize = 156MB == 128MB WB (at 0MB) + 32MB WB (at 128MB) + 4MB UC (at 156MB)
  */
 /* 2 MTRRS are reserved for the operating system */
 #if 1
 #define BIOS_MTRRS 6
 #define OS_MTRRS   2
 #else
 #define BIOS_MTRRS 8
 #define OS_MTRRS   0
 #endif
 #define MTRRS        (BIOS_MTRRS + OS_MTRRS)
 
 
 static void set_fixed_mtrrs(unsigned int first, unsigned int last, unsigned char type)
 {
 	unsigned int i;
 	unsigned int fixed_msr = NUM_FIXED_RANGES >> 3;
 	msr_t msr;
 	msr.lo = msr.hi = 0; /* Shut up gcc */
 	for(i = first; i < last; i++) {
 		/* When I switch to a new msr read it in */
 		if (fixed_msr != i >> 3) {
 			/* But first write out the old msr */
 			if (fixed_msr < (NUM_FIXED_RANGES >> 3)) {
 				disable_cache();
 				wrmsr(mtrr_msr[fixed_msr], msr);
 				enable_cache();
 			}
 			fixed_msr = i>>3;
 			msr = rdmsr(mtrr_msr[fixed_msr]);
 		}
 		if ((i & 7) < 4) {
 			msr.lo &= ~(0xff << ((i&3)*8));
 			msr.lo |= type << ((i&3)*8);
 		} else {
 			msr.hi &= ~(0xff << ((i&3)*8));
 			msr.hi |= type << ((i&3)*8);
 		}
 	}
 	/* Write out the final msr */
 	if (fixed_msr < (NUM_FIXED_RANGES >> 3)) {
 		disable_cache();
 		wrmsr(mtrr_msr[fixed_msr], msr);
 		enable_cache();
 	}
 }
 
 static unsigned fixed_mtrr_index(unsigned long addrk)
 {
 	unsigned index;
 	index = (addrk - 0) >> 6;
 	if (index >= 8) {
 		index = ((addrk - 8*64) >> 4) + 8;
 	}
 	if (index >= 24) {
 		index = ((addrk - (8*64 + 16*16)) >> 2) + 24;
 	}
 	if (index > NUM_FIXED_RANGES) {
 		index = NUM_FIXED_RANGES;
 	}
 	return index;
 }
 
 static unsigned int range_to_mtrr(unsigned int reg,
 	unsigned long range_startk, unsigned long range_sizek,
 	unsigned long next_range_startk, unsigned char type,
 	unsigned int address_bits, unsigned int above4gb)
 {
 	if (!range_sizek) {
 		/* If there's no MTRR hole, this function will bail out
 		 * here when called for the hole.
 		 */
 		printk(BIOS_SPEW, "Zero-sized MTRR range @%ldKB\n", range_startk);
 		return reg;
 	}
 
 	if (reg >= BIOS_MTRRS) {
 		printk(BIOS_ERR, "Warning: Out of MTRRs for base: %4ldMB, range: %ldMB, type %s\n",
 				range_startk >>10, range_sizek >> 10,
 				(type==MTRR_TYPE_UNCACHEABLE)?"UC":
 				   ((type==MTRR_TYPE_WRBACK)?"WB":"Other") );
 		return reg;
 	}
 
 	while(range_sizek) {
 		unsigned long max_align, align;
 		unsigned long sizek;
 		/* Compute the maximum size I can make a range */
 		max_align = fls(range_startk);
 		align = fms(range_sizek);
 		if (align > max_align) {
 			align = max_align;
 		}
 		sizek = 1 << align;
 		printk(BIOS_DEBUG, "Setting variable MTRR %d, base: %4ldMB, range: %4ldMB, type %s\n",
 			reg, range_startk >>10, sizek >> 10,
 			(type==MTRR_TYPE_UNCACHEABLE)?"UC":
 			    ((type==MTRR_TYPE_WRBACK)?"WB":"Other")
 			);
 
 		/* if range is above 4GB, MTRR is needed
 		 * only if above4gb flag is set
 		 */
 		if (range_startk < 0x100000000ull / 1024 || above4gb)
 			set_var_mtrr(reg++, range_startk, sizek, type, address_bits);
 		range_startk += sizek;
 		range_sizek -= sizek;
 		if (reg >= BIOS_MTRRS) {
 			printk(BIOS_ERR, "Running out of variable MTRRs!\n");
 			break;
 		}
 	}
 	return reg;
 }
 
 static unsigned long resk(uint64_t value)
 {
 	unsigned long resultk;
 	if (value < (1ULL << 42)) {
 		resultk = value >> 10;
 	}
 	else {
 		resultk = 0xffffffff;
 	}
 	return resultk;
 }
 
 static void set_fixed_mtrr_resource(void *gp, struct device *dev, struct resource *res)
 {
 	unsigned int start_mtrr;
 	unsigned int last_mtrr;
 	start_mtrr = fixed_mtrr_index(resk(res->base));
 	last_mtrr  = fixed_mtrr_index(resk((res->base + res->size)));
 	if (start_mtrr >= NUM_FIXED_RANGES) {
 		return;
 	}
 	printk(BIOS_DEBUG, "Setting fixed MTRRs(%d-%d) Type: WB\n",
 		start_mtrr, last_mtrr);
 	set_fixed_mtrrs(start_mtrr, last_mtrr, MTRR_TYPE_WRBACK);
 
 }
 
 #ifndef CONFIG_VAR_MTRR_HOLE
 #define CONFIG_VAR_MTRR_HOLE 1
 #endif
 
 struct var_mtrr_state {
 	unsigned long range_startk, range_sizek;
 	unsigned int reg;
 	unsigned long hole_startk, hole_sizek;
 	unsigned int address_bits;
 	unsigned int above4gb; /* Set if MTRRs are needed for DRAM above 4GB */
 };
 
 void set_var_mtrr_resource(void *gp, struct device *dev, struct resource *res)
 {
 	struct var_mtrr_state *state = gp;
 	unsigned long basek, sizek;
 	if (state->reg >= BIOS_MTRRS)
 		return;
 	basek = resk(res->base);
 	sizek = resk(res->size);
 	/* See if I can merge with the last range
 	 * Either I am below 1M and the fixed mtrrs handle it, or
 	 * the ranges touch.
 	 */
 	if ((basek <= 1024) || (state->range_startk + state->range_sizek == basek)) {
 		unsigned long endk = basek + sizek;
 		state->range_sizek = endk - state->range_startk;
 		return;
 	}
 	/* Write the range mtrrs */
 	if (state->range_sizek != 0) {
 #if CONFIG_VAR_MTRR_HOLE
 		if (state->hole_sizek == 0) {
 			/* We need to put that on to hole */
 			unsigned long endk = basek + sizek;
 			state->hole_startk = state->range_startk + state->range_sizek;
 			state->hole_sizek  = basek - state->hole_startk;
 			state->range_sizek = endk - state->range_startk;
 			return;
 		}
 #endif
 		state->reg = range_to_mtrr(state->reg, state->range_startk,
 			state->range_sizek, basek, MTRR_TYPE_WRBACK,
 			state->address_bits, state->above4gb);
 #if CONFIG_VAR_MTRR_HOLE
 		state->reg = range_to_mtrr(state->reg, state->hole_startk,
 			state->hole_sizek, basek, MTRR_TYPE_UNCACHEABLE,
 			state->address_bits, state->above4gb);
 #endif
 		state->range_startk = 0;
 		state->range_sizek = 0;
 		state->hole_startk = 0;
 		state->hole_sizek = 0;
 	}
 	/* Allocate an msr */
 	printk(BIOS_SPEW, " Allocate an msr - basek = %08lx, sizek = %08lx,\n", basek, sizek);
 	state->range_startk = basek;
 	state->range_sizek  = sizek;
 }
 
 void x86_setup_fixed_mtrrs(void)
 {
         /* Try this the simple way of incrementally adding together
          * mtrrs.  If this doesn't work out we can get smart again
          * and clear out the mtrrs.
          */
 
         printk(BIOS_DEBUG, "\n");
         /* Initialized the fixed_mtrrs to uncached */
         printk(BIOS_DEBUG, "Setting fixed MTRRs(%d-%d) Type: UC\n",
 	        0, NUM_FIXED_RANGES);
         set_fixed_mtrrs(0, NUM_FIXED_RANGES, MTRR_TYPE_UNCACHEABLE);
 
         /* Now see which of the fixed mtrrs cover ram.
                  */
         search_global_resources(
 		IORESOURCE_MEM | IORESOURCE_CACHEABLE, IORESOURCE_MEM | IORESOURCE_CACHEABLE,
 		set_fixed_mtrr_resource, NULL);
         printk(BIOS_DEBUG, "DONE fixed MTRRs\n");
 
         /* enable fixed MTRR */
         printk(BIOS_SPEW, "call enable_fixed_mtrr()\n");
         enable_fixed_mtrr();
 
 }
 
 void x86_setup_var_mtrrs(unsigned int address_bits, unsigned int above4gb)
 /* this routine needs to know how many address bits a given processor
  * supports.  CPUs get grumpy when you set too many bits in
  * their mtrr registers :(  I would generically call cpuid here
  * and find out how many physically supported but some cpus are
  * buggy, and report more bits then they actually support.
  * If above4gb flag is set, variable MTRR ranges must be used to
  * set cacheability of DRAM above 4GB. If above4gb flag is clear,
  * some other mechanism is controlling cacheability of DRAM above 4GB.
  */
 {
 	/* Try this the simple way of incrementally adding together
 	 * mtrrs.  If this doesn't work out we can get smart again
 	 * and clear out the mtrrs.
 	 */
 	struct var_mtrr_state var_state;
 
 	/* Cache as many memory areas as possible */
 	/* FIXME is there an algorithm for computing the optimal set of mtrrs?
 	 * In some cases it is definitely possible to do better.
 	 */
 	var_state.range_startk = 0;
 	var_state.range_sizek = 0;
 	var_state.hole_startk = 0;
 	var_state.hole_sizek = 0;
 	var_state.reg = 0;
 	var_state.address_bits = address_bits;
 	var_state.above4gb = above4gb;
 
 	search_global_resources(
 		IORESOURCE_MEM | IORESOURCE_CACHEABLE, IORESOURCE_MEM | IORESOURCE_CACHEABLE,
 		set_var_mtrr_resource, &var_state);
 
 #if (CONFIG_GFXUMA == 1) /* UMA or SP. */
 	/* For now we assume the UMA space is at the end of memory below 4GB */
 	if (var_state.hole_startk || var_state.hole_sizek) {
 		printk(BIOS_DEBUG, "Warning: Can't set up MTRR hole for UMA due to pre-existing MTRR hole.\n");
 	} else {
 #if CONFIG_VAR_MTRR_HOLE
 		// Increase the base range and set up UMA as an UC hole instead
 		var_state.range_sizek += (uma_memory_size >> 10);
 
 		var_state.hole_startk = (uma_memory_base >> 10);
 		var_state.hole_sizek = (uma_memory_size >> 10);
 #endif
 	}
 #endif
 	/* Write the last range */
 	var_state.reg = range_to_mtrr(var_state.reg, var_state.range_startk,
 		var_state.range_sizek, 0, MTRR_TYPE_WRBACK,
 		var_state.address_bits, var_state.above4gb);
 #if CONFIG_VAR_MTRR_HOLE
 	var_state.reg = range_to_mtrr(var_state.reg, var_state.hole_startk,
 		var_state.hole_sizek, 0, MTRR_TYPE_UNCACHEABLE,
 		var_state.address_bits, var_state.above4gb);
 #endif
 	printk(BIOS_DEBUG, "DONE variable MTRRs\n");
 	printk(BIOS_DEBUG, "Clear out the extra MTRR's\n");
 	/* Clear out the extra MTRR's */
 	while(var_state.reg < MTRRS) {
 		set_var_mtrr(var_state.reg++, 0, 0, 0, var_state.address_bits);
 	}
+
+#if CONFIG_CACHE_ROM
+	/* Enable Caching and speculative Reads for the
+	 * complete ROM now that we actually have RAM.
+	 */
+	if (boot_cpu() && (acpi_slp_type != 3)) {
+		set_var_mtrr(7, (4096-4)*1024, 4*1024,
+			MTRR_TYPE_WRPROT, address_bits);
+	}
+#endif
+
 	printk(BIOS_SPEW, "call enable_var_mtrr()\n");
 	enable_var_mtrr();
 	printk(BIOS_SPEW, "Leave %s\n", __func__);
 	post_code(0x6A);
 }
 
 
 void x86_setup_mtrrs(void)
 {
 	int address_size;
 	x86_setup_fixed_mtrrs();
 	address_size = cpu_phys_address_size();
 	printk(BIOS_DEBUG, "CPU physical address size: %d bits\n", address_size);
 	x86_setup_var_mtrrs(address_size, 1);
 }
 
 
 int x86_mtrr_check(void)
 {
 	/* Only Pentium Pro and later have MTRR */
 	msr_t msr;
 	printk(BIOS_DEBUG, "\nMTRR check\n");
 
 	msr = rdmsr(0x2ff);
 	msr.lo >>= 10;
 
 	printk(BIOS_DEBUG, "Fixed MTRRs   : ");
 	if (msr.lo & 0x01)
 		printk(BIOS_DEBUG, "Enabled\n");
 	else
 		printk(BIOS_DEBUG, "Disabled\n");
 
 	printk(BIOS_DEBUG, "Variable MTRRs: ");
 	if (msr.lo & 0x02)
 		printk(BIOS_DEBUG, "Enabled\n");
 	else
 		printk(BIOS_DEBUG, "Disabled\n");
 
 	printk(BIOS_DEBUG, "\n");
 
 	post_code(0x93);
 	return ((int) msr.lo);
 }
diff --git a/src/include/cpu/x86/lapic.h b/src/include/cpu/x86/lapic.h
index 68608ed..2215ec7 100644
--- a/src/include/cpu/x86/lapic.h
+++ b/src/include/cpu/x86/lapic.h
@@ -1,159 +1,160 @@
 #ifndef CPU_X86_LAPIC_H
 #define CPU_X86_LAPIC_H
 
 #include <cpu/x86/lapic_def.h>
 #include <cpu/x86/msr.h>
 #include <arch/hlt.h>
 
 /* See if I need to initialize the local apic */
 #if CONFIG_SMP || CONFIG_IOAPIC
 #  define NEED_LAPIC 1
 #else
 #  define NEED_LAPIC 0
 #endif
 
 static inline __attribute__((always_inline)) unsigned long lapic_read(unsigned long reg)
 {
 	return *((volatile unsigned long *)(LAPIC_DEFAULT_BASE+reg));
 }
 
 static inline __attribute__((always_inline)) void lapic_write(unsigned long reg, unsigned long v)
 {
 	*((volatile unsigned long *)(LAPIC_DEFAULT_BASE+reg)) = v;
 }
 
 static inline __attribute__((always_inline)) void lapic_wait_icr_idle(void)
 {
 	do { } while ( lapic_read( LAPIC_ICR ) & LAPIC_ICR_BUSY );
 }
 
-
-
 static inline void enable_lapic(void)
 {
 
 	msr_t msr;
 	msr = rdmsr(LAPIC_BASE_MSR);
 	msr.hi &= 0xffffff00;
 	msr.lo &= 0x000007ff;
 	msr.lo |= LAPIC_DEFAULT_BASE | (1 << 11);
 	wrmsr(LAPIC_BASE_MSR, msr);
 }
 
 static inline void disable_lapic(void)
 {
 	msr_t msr;
 	msr = rdmsr(LAPIC_BASE_MSR);
 	msr.lo &= ~(1 << 11);
 	wrmsr(LAPIC_BASE_MSR, msr);
 }
 
 static inline __attribute__((always_inline)) unsigned long lapicid(void)
 {
 	return lapic_read(LAPIC_ID) >> 24;
 }
 
-
+#ifndef __ROMCC__
 #if CONFIG_AP_IN_SIPI_WAIT != 1
 /* If we need to go back to sipi wait, we use the long non-inlined version of
  * this function in lapic_cpu_init.c
  */
 static inline __attribute__((always_inline)) void stop_this_cpu(void)
 {
 	/* Called by an AP when it is ready to halt and wait for a new task */
 	for(;;) {
 		hlt();
 	}
 }
 #else
 void stop_this_cpu(void);
 #endif
 
 #if !defined(__PRE_RAM__)
 
 #define xchg(ptr,v) ((__typeof__(*(ptr)))__xchg((unsigned long)(v),(ptr),sizeof(*(ptr))))
 
 struct __xchg_dummy { unsigned long a[100]; };
 #define __xg(x) ((struct __xchg_dummy *)(x))
 
 /*
  * Note: no "lock" prefix even on SMP: xchg always implies lock anyway
  * Note 2: xchg has side effect, so that attribute volatile is necessary,
  *	  but generally the primitive is invalid, *ptr is output argument. --ANK
  */
 static inline unsigned long __xchg(unsigned long x, volatile void * ptr, int size)
 {
 	switch (size) {
 		case 1:
 			__asm__ __volatile__("xchgb %b0,%1"
 				:"=q" (x)
 				:"m" (*__xg(ptr)), "0" (x)
 				:"memory");
 			break;
 		case 2:
 			__asm__ __volatile__("xchgw %w0,%1"
 				:"=r" (x)
 				:"m" (*__xg(ptr)), "0" (x)
 				:"memory");
 			break;
 		case 4:
 			__asm__ __volatile__("xchgl %0,%1"
 				:"=r" (x)
 				:"m" (*__xg(ptr)), "0" (x)
 				:"memory");
 			break;
 	}
 	return x;
 }
 
 static inline void lapic_write_atomic(unsigned long reg, unsigned long v)
 {
 	(void)xchg((volatile unsigned long *)(LAPIC_DEFAULT_BASE+reg), v);
 }
 
 
 #ifdef X86_GOOD_APIC
 # define FORCE_READ_AROUND_WRITE 0
 # define lapic_read_around(x) lapic_read(x)
 # define lapic_write_around(x,y) lapic_write((x),(y))
 #else
 # define FORCE_READ_AROUND_WRITE 1
 # define lapic_read_around(x) lapic_read(x)
 # define lapic_write_around(x,y) lapic_write_atomic((x),(y))
 #endif
 
 static inline int lapic_remote_read(int apicid, int reg, unsigned long *pvalue)
 {
 	int timeout;
 	unsigned long status;
 	int result;
 	lapic_wait_icr_idle();
 	lapic_write_around(LAPIC_ICR2, SET_LAPIC_DEST_FIELD(apicid));
 	lapic_write_around(LAPIC_ICR, LAPIC_DM_REMRD | (reg >> 4));
 	timeout = 0;
 	do {
 #if 0
 		udelay(100);
 #endif
 		status = lapic_read(LAPIC_ICR) & LAPIC_ICR_RR_MASK;
 	} while (status == LAPIC_ICR_RR_INPROG && timeout++ < 1000);
 
 	result = -1;
 	if (status == LAPIC_ICR_RR_VALID) {
 		*pvalue = lapic_read(LAPIC_RRR);
 		result = 0;
 	}
 	return result;
 }
 
 
 void setup_lapic(void);
 
 #if CONFIG_SMP == 1
 struct device;
 int start_cpu(struct device *cpu);
 #endif /* CONFIG_SMP */
 
 #endif /* !__PRE_RAM__ */
 
+int boot_cpu(void);
+#endif
+
 #endif /* CPU_X86_LAPIC_H */
